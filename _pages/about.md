---
layout: about
title: About
permalink: /
subtitle: Postdoctoral Researcher  | <a href='https://www.mpi-sp.org/'>MPI-SP, Germany</a>

profile:
  align: right
  image: my_profile_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p></p>
    <p></p>

news: true # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hello! My name is Megha (she/her). I am a Postdoctoral Researcher at [Max Planck Institute for Security and Privacy (MPI-SP)](https://www.mpi-sp.org/) in Data Science for Humanity Group, advised by [Meeyoung Cha](https://en.wikipedia.org/wiki/Cha_Meeyoung). My research interest lies at the intersection of Natural Language Processing (NLP) and Computational Social Science (CSS), with a focus on misinformation, online narratives, bias mitigation, and information integrity.

Before joining MPI-SP, I completed my PhD in Computer Science & Engineering at [IIIT-Delhi, India](https://www.iiitd.ac.in/). My doctoral research, supervised by [Dr. Tanmoy Chakraborty](https://tanmoychak.com/) and [Dr. Md Shad Akhtar](https://faculty.iiitd.ac.in/~shad.akhtar/), examined the “Genesis and spread of online claims in the context of misinformation.” I am passionate about developing AI-driven methods that support fact-checking and improve the situation of digital information ecosystems.

During my PhD, I had the opportunity to work as a Visiting Researcher at the [Mohamed bin Zayed University of Artificial Intelligence](https://mbzuai.ac.ae/), where I collaborated with [Prof. Preslav Nakov](https://mbzuai.ac.ae/study/faculty/preslav-nakov/) on projects aimed at claim normalization and simplification in social media posts. My earlier academic journey includes a Master’s in Computer Science from the University of Delhi, where I explored fake profile detection on online platforms.


Thank you for visiting my website! I am always interested in meaningful collaborations in the areas of factuality and biases in LLMs, computational social sciences, and responsible AI. Feel free to reach out if you’d like to discuss research ideas, or potential collaborations.